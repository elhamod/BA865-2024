{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNJvycnzpkp9wCyAMbZChld",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elhamod/BA865-2024/blob/main/hands-on/First_Pytorch_NN_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Welcome to your first PyTorch Neural Net!"
      ],
      "metadata": {
        "id": "W8H546tNarSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Things we will investigate:\n",
        "\n",
        "- How to load and pre-process the data.\n",
        "- How to construct an MLP.\n",
        "- How to train an MLP (Loss and optimization).\n",
        "- How to utilize a GPU.\n",
        "- How the complexity of the model affects its performance.\n",
        "- How to measure the performance of the model.\n",
        "- The effects of hyper-parameters:\n",
        "  - Learning rate.\n",
        "  - Optimizer.\n",
        "  - Batch size.\n",
        "- How to use WandB.\n",
        "- Using SCC.\n"
      ],
      "metadata": {
        "id": "Gt1GCe9Kuzee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import some packages"
      ],
      "metadata": {
        "id": "frEXdeTWNXqt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "B-8PrSb5Idis"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This helps you check if GPU is available"
      ],
      "metadata": {
        "id": "0BNuG94i373o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd7mgN-abpJB",
        "outputId": "fed06779-15da-47c0-db6f-3b2c0fcb60e5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some extra fancy but optional packages:\n",
        "\n",
        "- `torchmetrics` for calculating accuracy\n",
        "- `wandb` for logging"
      ],
      "metadata": {
        "id": "9nYYpgwD3_-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U torchmetrics"
      ],
      "metadata": {
        "id": "ITkvFTCHbdOn"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install wandb -qU\n",
        "# import wandb\n",
        "# wandb.login()"
      ],
      "metadata": {
        "id": "e8unrZajZigs"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper-parameters\n",
        "\n",
        "Define your hyper-parameters here."
      ],
      "metadata": {
        "id": "dJUP7ISFNbHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "\n",
        "# Data\n",
        "input_size = 28 * 28  # MNIST images are 28x28\n",
        "output_size = 10  # 10 classes for the digits 0-9\n",
        "batch_size = 64\n",
        "\n",
        "# MLP\n",
        "hidden_size = 128\n",
        "\n",
        "#Optimzation\n",
        "learning_rate = 0.001\n",
        "epochs = 3"
      ],
      "metadata": {
        "id": "fp6onSYaJNjN"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "Load your dataset and create `DataLoaders` that handle the batching and shuffling."
      ],
      "metadata": {
        "id": "VWFOwqDtNeG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "wTgFHFDMJTe5"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define and create your model"
      ],
      "metadata": {
        "id": "O43tOiHANfHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    # Defines the forward pass.\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, input_size)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Could also be written as this:\n",
        "# class MLP(nn.Module):\n",
        "#     def __init__(self, input_size, hidden_size, output_size):\n",
        "#         super(MLP, self).__init__()\n",
        "#         self.model = nn.Sequential(\n",
        "#             nn.Linear(input_size, hidden_size),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(hidden_size, output_size)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = x.view(-1, input_size)\n",
        "#         x = self.model(x)\n",
        "#         return x\n"
      ],
      "metadata": {
        "id": "dVLVk-DmJVFc"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding `.cuda` moves your model to the GPU."
      ],
      "metadata": {
        "id": "R9N6B87Y4pO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(input_size, hidden_size, output_size)#.cuda()"
      ],
      "metadata": {
        "id": "eRrS3D6gJVHx"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss\n",
        "\n",
        "For classification, we use cross-entropy."
      ],
      "metadata": {
        "id": "RiPIJNAaNirU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "S4LHoaZaJXd1"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Optimizer"
      ],
      "metadata": {
        "id": "PtHuHVcSNjrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "HYtLekcnJYgt"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training!"
      ],
      "metadata": {
        "id": "slsVWSc_Nk6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.init(\n",
        "#     # Set the project where this run will be logged\n",
        "#     project=\"First PyTorch NN\",\n",
        "#     # We pass a run name (otherwise itâ€™ll be randomly assigned, like sunshine-lollypop-10)\n",
        "#     name=\"experiment_2\",\n",
        "#     # Track hyperparameters and run metadata\n",
        "#     config={\n",
        "#     \"learning_rate\": learning_rate,\n",
        "#     \"epochs\": epochs,\n",
        "#     \"notes for me\": \"This is a very lovely experiment. please work!\"\n",
        "#     })"
      ],
      "metadata": {
        "id": "8MrmIuolgDFE"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torchmetrics\n",
        "# Define the accuracy metric\n",
        "# train_accuracy = torchmetrics.Accuracy()\n",
        "\n",
        "\n",
        "train_acc = 0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs): # The epochs.\n",
        "    for i, (images, labels) in enumerate(train_loader): # The batches.\n",
        "        # step 1: Zero out the gradients.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # step 1.1 move data to cuda. Make sure the model is on cuda too!\n",
        "        #images = images.cuda\n",
        "        #labels = labels.cuda()\n",
        "\n",
        "        # step2: Forward pass\n",
        "        outputs = model(images) #images.cuda\n",
        "\n",
        "        # step 3: calculate the loss.\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # step 4: Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # step 5: (optional) calculate accuracy\n",
        "        # train_accuracy.update(outputs, labels)\n",
        "        train_acc = train_acc + torch.sum(torch.argmax(outputs, axis=1) == labels)\n",
        "\n",
        "        # Print the loss\n",
        "        if i %100 == 0:\n",
        "          print(\"Epoch\", epoch+ 1, \" batch\", i, \": \", loss.item())\n",
        "\n",
        "    # Compute total train accuracy\n",
        "    # train_acc = train_accuracy.compute()\n",
        "    # train_accuracy.reset()\n",
        "    train_acc = train_acc/len(train_dataset)\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Train Accuracy: {train_acc.item():.4f}')\n",
        "    # wandb.log({\"train_accuracy\": train_acc, \"loss\": loss})\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNhVx_muJcfy",
        "outputId": "4c5dcb7a-79fa-4826-ffc9-b05c1366a1a0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1  batch 0 :  2.3279385566711426\n",
            "Epoch 1  batch 100 :  0.4409348964691162\n",
            "Epoch 1  batch 200 :  0.2814260423183441\n",
            "Epoch 1  batch 300 :  0.22777119278907776\n",
            "Epoch 1  batch 400 :  0.4258238673210144\n",
            "Epoch 1  batch 500 :  0.2658941447734833\n",
            "Epoch 1  batch 600 :  0.3383975028991699\n",
            "Epoch 1  batch 700 :  0.14792561531066895\n",
            "Epoch 1  batch 800 :  0.2226632982492447\n",
            "Epoch 1  batch 900 :  0.1953068971633911\n",
            "Epoch [1/3], Train Accuracy: 0.8880\n",
            "Epoch 2  batch 0 :  0.3055928349494934\n",
            "Epoch 2  batch 100 :  0.3321334421634674\n",
            "Epoch 2  batch 200 :  0.17917245626449585\n",
            "Epoch 2  batch 300 :  0.24423947930335999\n",
            "Epoch 2  batch 400 :  0.36964285373687744\n",
            "Epoch 2  batch 500 :  0.1722712516784668\n",
            "Epoch 2  batch 600 :  0.224585622549057\n",
            "Epoch 2  batch 700 :  0.16651535034179688\n",
            "Epoch 2  batch 800 :  0.32655808329582214\n",
            "Epoch 2  batch 900 :  0.10728760063648224\n",
            "Epoch [2/3], Train Accuracy: 0.9406\n",
            "Epoch 3  batch 0 :  0.06462714821100235\n",
            "Epoch 3  batch 100 :  0.06736205518245697\n",
            "Epoch 3  batch 200 :  0.11374882608652115\n",
            "Epoch 3  batch 300 :  0.10052809119224548\n",
            "Epoch 3  batch 400 :  0.042420532554388046\n",
            "Epoch 3  batch 500 :  0.2419872283935547\n",
            "Epoch 3  batch 600 :  0.09083593636751175\n",
            "Epoch 3  batch 700 :  0.24833519756793976\n",
            "Epoch 3  batch 800 :  0.19258330762386322\n",
            "Epoch 3  batch 900 :  0.06022082269191742\n",
            "Epoch [3/3], Train Accuracy: 0.9566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "TLhvpPZ2Nmep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test_accuracy = torchmetrics.Accuracy()\n",
        "\n",
        "# Test the model\n",
        "test_acc = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Compute test accuracy\n",
        "        # test_accuracy.update(outputs, labels)\n",
        "        test_acc = test_acc + torch.sum(torch.argmax(outputs, axis=1) == labels)\n",
        "\n",
        "    test_acc = test_acc/len(test_dataset)\n",
        "    # test_acc = test_accuracy.compute()\n",
        "    # test_accuracy.reset()\n",
        "\n",
        "    print(f'Test Accuracy: {test_acc:.4f}')\n",
        "    # wandb.summary['test_accuracy'] = test_acc\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYLTEnn3NWCh",
        "outputId": "0b3a7412-6e9c-4a1f-f8f3-95f364dd25ac"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.finish()"
      ],
      "metadata": {
        "id": "eWlDbw_cacL6"
      },
      "execution_count": 60,
      "outputs": []
    }
  ]
}